{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from model.dataset import SNEMI3DDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from model.unet import UNet\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import model.metrics as metrics\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import model.loss as loss\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "expriment_name = \"VILoss_1\"\n",
    "lossFunc = loss.HomeMadeBCE_withClassBalance()\n",
    "\n",
    "# 100 0.5053152359607173 0.19049978520827424 20570595.0 84287005.0\n",
    "\n",
    "cwd = os.getcwd()\n",
    "curResultDir = cwd + \"/results/\" + expriment_name + \"/\"\n",
    "os.makedirs(curResultDir, exist_ok=True)\n",
    "\n",
    "numFile = 100\n",
    "fileList = [i for i in range(numFile)]\n",
    "\n",
    "fold_num = 3\n",
    "kf = KFold(n_splits=fold_num, shuffle=True)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "# TODO: Normalize whole dataset by its mean and std\n",
    "\n",
    "# What to do each eoch\n",
    "# 1. train, log training loss\n",
    "# 2. validate, log metrics, save model in a early stopping manner, log all metrics\n",
    "# What to do each experiment:\n",
    "# Set experiment name\n",
    "# save all in the parameter name\n",
    "# Generate illustration if needed\n",
    "\n",
    "for fold, (train_and_val_list, test_list) in enumerate(kf.split(fileList)):\n",
    "\n",
    "    print(\"fold: \" + str(fold))\n",
    "\n",
    "    train_size = int(0.8 * len(train_and_val_list))\n",
    "    val_size = len(train_and_val_list) - train_size\n",
    "\n",
    "    print(type(train_and_val_list))\n",
    "\n",
    "    train_list = random.sample(train_and_val_list.tolist(), train_size)\n",
    "    val_size = [i for i in train_and_val_list if i not in train_list]\n",
    "\n",
    "    train_dataset = SNEMI3DDataset(train_list, augmentation=True)\n",
    "    val_dataset = SNEMI3DDataset(train_list, augmentation=False)\n",
    "    test_dataset = SNEMI3DDataset(test_list, augmentation=False)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    epoch_num = 50\n",
    "\n",
    "    unet = UNet()\n",
    "\n",
    "    unet.cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(unet.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)\n",
    "\n",
    "    vi_record = []\n",
    "    curmin_vi = None\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        print(\"epoch: \", epoch)\n",
    "\n",
    "        t1 = time.time()\n",
    "\n",
    "        unet.train()\n",
    "        for image, mask in train_dataloader:\n",
    "            image = image.cuda()\n",
    "            mask = mask.cuda()\n",
    "            pred = torch.softmax(unet(image), 1)\n",
    "            # print(pred.shape, mask.shape)\n",
    "            loss = lossFunc(mask, pred)\n",
    "            print(loss)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(unet.parameters(), 5)\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        t2 = time.time()\n",
    "\n",
    "        print(\"train time: \", t2 - t1)\n",
    "\n",
    "        # torch.save(unet.state_dict(), \"epoch_\" + str(i) + \".pth\")\n",
    "\n",
    "        # validation\n",
    "        vi = 0.\n",
    "        images = []\n",
    "        masks = []\n",
    "        preds = []\n",
    "        vis = []\n",
    "        for index, (image, mask) in enumerate(val_dataloader):\n",
    "            unet.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = torch.softmax(unet(image.cuda()), 1)[:, 1:2, :, :]\n",
    "                images.append(image.squeeze().numpy())\n",
    "                masks.append(mask.squeeze().numpy())\n",
    "                preds.append(pred.cpu().squeeze().numpy())\n",
    "                if epoch % 2 == 0 and index == 0:\n",
    "                    fig, axes = plt.subplots(1,4)\n",
    "                    axes[0].imshow(image.squeeze().numpy())\n",
    "                    axes[1].imshow(mask.squeeze().numpy())\n",
    "                    axes[2].imshow(pred.cpu().squeeze().numpy())\n",
    "                    axes[3].imshow((pred.cpu().squeeze().numpy() > 0.5).astype(int))\n",
    "                    plt.show()\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            vis = list(executor.map(metrics.vi, masks, preds))\n",
    "        vi = np.mean(vis)\n",
    "\n",
    "        t3 = time.time()\n",
    "        print(\"val time: \", t3 - t2)\n",
    "\n",
    "        vi_record.append(vi)\n",
    "        result = pd.DataFrame({\n",
    "            \"Epoch\": [epoch],\n",
    "            \"VI\": [vi],\n",
    "        })\n",
    "        if not os.path.exists(curResultDir + \"fold_\" + str(fold) + \"_val_result.csv\"):\n",
    "            result.to_csv(curResultDir + \"fold_\" + str(fold) + \"_val_result.csv\", index=False)\n",
    "        else:\n",
    "            result.to_csv(curResultDir + \"fold_\" + str(fold) + \"_val_result.csv\", mode='a', header=False, index=False)\n",
    "\n",
    "        if curmin_vi == None or vi < curmin_vi:\n",
    "            curmin_vi = vi\n",
    "            torch.save(unet.state_dict(), curResultDir + \"fold_\" + str(fold) + \"_best_model_state.pth\")\n",
    "\n",
    "        print(\"saving time: \", time.time() - t3)\n",
    "\n",
    "        print(\"epoch: \" + str(epoch) + \" VI: \" + str(vi))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
